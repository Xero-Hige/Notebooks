{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OaXRf8dbe_4"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "\n",
        "model = torchvision.models.resnet18(weights='IMAGENET1K_V1')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning\n",
        "\n",
        "Para hacer finetuning tenemos que reentrenar (pero solo un poco) todo el modelo."
      ],
      "metadata": {
        "id": "oSrA4zTfZu7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "VJEvWwZDZpqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning\n",
        "\n",
        "Para \"hacer\" transfer learning no necesito entrenar todas las capas, pero voy a reemplazar algunas de las ultimas en funcion de la nueva tarea que quiero que realicen."
      ],
      "metadata": {
        "id": "_nk_jA7ic7XH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc.in_features"
      ],
      "metadata": {
        "id": "yEHQVpM6b9bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "YdO9r_s7ctWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso reemplazar la ultima capa por una capa propia para la tarea que queremos"
      ],
      "metadata": {
        "id": "LLTD5-ncdLh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)"
      ],
      "metadata": {
        "id": "BfJvZ1Secyvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "_pFqVvSMdaCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yapa: podemos usar de PyTorch el learning rate scheduler para ir reduciendo de a poco el learning rate y aumentar la velocidad a la que converge el modelo."
      ],
      "metadata": {
        "id": "NcLRFrgEeLM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import lr_scheduler\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "CAQmJIn4eAEw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}