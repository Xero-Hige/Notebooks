{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "7Q5Liv_Gnkfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# W2V casero\n",
        "\n",
        "_we have w2v at home_\n",
        "\n",
        "**W2V at home**:"
      ],
      "metadata": {
        "id": "LlnPCjk3cpif"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7K_TJHsiJU8"
      },
      "outputs": [],
      "source": [
        "TOKENS_DIMS = 6\n",
        "EMBEDING_DIMS = 3\n",
        "\n",
        "class MyW2V(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyW2V,self).__init__()\n",
        "\n",
        "        #TOKENS_DIMS > EMBEDING_DIMS\n",
        "        self.entrada = nn.Linear(TOKENS_DIMS,EMBEDING_DIMS)\n",
        "\n",
        "        self.salida = nn.Linear(EMBEDING_DIMS,TOKENS_DIMS*2)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        embeding = self.entrada(x)\n",
        "\n",
        "        print(\"Embed:\",embeding.detach(),\"\\n\\n\")\n",
        "\n",
        "        contexto = self.salida(embeding)\n",
        "\n",
        "        return F.sigmoid(contexto)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_w2v = MyW2V()"
      ],
      "metadata": {
        "id": "bbWJ77C0ns_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palabra = [0,1,0,0,0,0] #One Hot"
      ],
      "metadata": {
        "id": "7O_1savTn2bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    out = modelo_w2v(torch.FloatTensor(palabra))"
      ],
      "metadata": {
        "id": "odVPsQsOn8gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab964d6-0210-48b6-d977-6573d30514e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embed: tensor([0.2573, 0.7073, 0.2625]) \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array(out)\n",
        "print (\"Token anterior:\",arr[0:6])\n",
        "print (\"Token siguiente:\",arr[6:])"
      ],
      "metadata": {
        "id": "V81jyvkEPuoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09a42bc-4022-4203-c4c8-38a9d4f9701b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token anterior: [0.48409918 0.65864915 0.63109267 0.42371115 0.5730252  0.4519871 ]\n",
            "Token siguiente: [0.4506114  0.3936926  0.4334302  0.62619776 0.38475502 0.6177196 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# W2V casero (receta familiar)"
      ],
      "metadata": {
        "id": "81zxNcy4vFGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TOKENS_DIMS = 6 #Corpus size\n",
        "EMBEDING_DIMS = 3\n",
        "\n",
        "class MyW2V(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyW2V,self).__init__()\n",
        "\n",
        "        #TOKENS_DIMS > EMBEDING_DIMS\n",
        "        self.entrada = nn.Embedding(TOKENS_DIMS,EMBEDING_DIMS)\n",
        "\n",
        "        self.salida = nn.Linear(EMBEDING_DIMS,TOKENS_DIMS*2)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        embeding = self.entrada(x)\n",
        "\n",
        "        print(\"Embed:\",embeding.detach(),\"\\n\\n\")\n",
        "\n",
        "        contexto = self.salida(embeding)\n",
        "\n",
        "        return F.sigmoid(contexto)"
      ],
      "metadata": {
        "id": "zVgmcY67sVbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_w2v = MyW2V()\n",
        "palabra = [1]"
      ],
      "metadata": {
        "id": "LyPxrLxqtY_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    out = modelo_w2v(torch.LongTensor(palabra))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7iUiY20tjOi",
        "outputId": "c1dbb2e4-19e9-4ff7-9d16-74dc119ac6be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embed: tensor([[-0.8128, -0.2875, -0.4248]]) \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array(out)[0]\n",
        "print (\"Token anterior:\",arr[0:6]) - [1,0,0,0,0,0]\n",
        "print (\"Token siguiente:\",arr[6:]) - [0,0,0,0,0,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2c87X4rtmQ0",
        "outputId": "5bd99b17-efdb-40b5-9c93-dd839df95811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token anterior: [0.70831823 0.6361399  0.43203884 0.4184158  0.70599496 0.4467238 ]\n",
            "Token siguiente: [0.55267584 0.5883149  0.46864602 0.5090868  0.42227638 0.5129961 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lobo = [.5,.5,.3]\n",
        "\n",
        "[0.70831823 0.6361399  0.43203884 0.4184158  0.70599496 0.4467238 ],[0.55267584 0.5883149  0.46864602 0.5090868  0.42227638 0.5129961 ]\n",
        "[1,0,0,0,0,0],[0,0,0,0,0,1]"
      ],
      "metadata": {
        "id": "SpBFmlu-VKmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SDQmtFwmV8uI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}